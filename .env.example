# Entrenai Application Configuration
PYTHON_VERSION=3.10
LOG_LEVEL=INFO

# Host Port Mappings (defaults from docker-compose.yml)
FASTAPI_HOST_PORT=8000
MOODLE_HOST_PORT=8080
MOODLE_HOST_SSL_PORT=8443
PGVECTOR_HOST_PORT=5432
OLLAMA_HOST_PORT=11434
N8N_HOST_PORT=5678
REDIS_HOST_PORT=6379

FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000

# Data and File Paths
DATA_DIR=data # Base directory for application data (e.g., SQLite DBs, downloads)
FILE_TRACKER_DB_NAME=file_tracker.sqlite # SQLite database name for tracking processed files
DOWNLOAD_SUBDIR=downloads # Subdirectory within DATA_DIR for downloaded Moodle files

# Moodle Configuration
MOODLE_URL=http://localhost:8080 # Adjust if Moodle runs on a different port in Docker
MOODLE_TOKEN=your_moodle_web_service_token
MOODLE_COURSE_FOLDER_NAME="Entrenai Documents" # Name of the folder to be created in Moodle courses
MOODLE_REFRESH_LINK_NAME="Refresh Entrenai IA"
MOODLE_CHAT_LINK_NAME="Chat con Entrenai IA"
MOODLE_DEFAULT_TEACHER_ID=2 # Example Moodle User ID for the teacher (often admin is 2)

# Pgvector Configuration
PGVECTOR_HOST=pgvector_db # Service name for inter-container communication. For host access, use localhost:PGVECTOR_HOST_PORT
PGVECTOR_PORT=5433 # Host port as mapped in docker-compose
PGVECTOR_USER=pgvector_user
PGVECTOR_PASSWORD=pgvector_password
PGVECTOR_DB_NAME=pgvector_db
PGVECTOR_COLLECTION_PREFIX="entrenai_course_" # Prefix for table names (collections)
DEFAULT_VECTOR_SIZE=384 # Default vector size for embeddings (e.g., for nomic-embed-text)

# Celery Configuration
CELERY_BROKER_URL=redis://redis:6379/0 # Service name for inter-container communication. For host access, use redis://localhost:REDIS_HOST_PORT/0
CELERY_RESULT_BACKEND=redis://redis:6379/0 # For local development, use redis://redis:6379/0 if API is in Docker

# N8N Configuration
N8N_URL=http://n8n:5678 # Service name for inter-container communication. For host access, use http://localhost:N8N_HOST_PORT
N8N_WEBHOOK_URL=http://localhost:5678 # N8N's own webhook URL, often same as N8N_URL
N8N_API_KEY=your_n8n_api_key # If N8N is secured with an API key for its REST API
N8N_CHAT_WORKFLOW_ID= # Optional: Specific ID of a pre-existing chat workflow in N8N
N8N_WORKFLOW_JSON_PATH="src/entrenai/n8n_workflow.json" # Path to the N8N workflow JSON file to import
N8N_ENCRYPTION_KEY= # A secure random string for N8N data encryption (used by N8N itself)

# --- Docker Compose Specific Variables ---
# These are typically used by docker-compose.yml directly or by the services within it.

# Moodle Docker Configuration
MOODLE_DB_HOST=moodle_db
MOODLE_DB_PORT=5432
MOODLE_DB_USER=moodle_user
MOODLE_DB_PASSWORD=moodle_password
MOODLE_DB_NAME=moodle_db
MOODLE_USERNAME=admin # Moodle admin user
MOODLE_PASSWORD=admin_password # Moodle admin password
MOODLE_EMAIL=admin@example.com
MOODLE_SITENAME="Entrenai Moodle"
# MOODLE_REVERSEPROXY - set to true if moodle is behind a reverse proxy

# N8N Docker Configuration
N8N_DB_HOST=n8n_db
N8N_DB_PORT=5432
N8N_DB_USER=n8n_user
N8N_DB_PASSWORD=n8n_password
N8N_DB_NAME=n8n_db
N8N_DB_HOST=n8n_db

# PostgreSQL common settings (can be overridden per service if needed)
POSTGRES_INITDB_ARGS="--auth-host=scram-sha-256"
POSTGRES_HOST_AUTH_METHOD=scram-sha-256

# Ollama Docker Configuration
# OLLAMA_MODELS_VOLUME_PATH=./ollama_models # Path to persist Ollama models on the host

# Pgvector Docker Configuration
PGVECTOR_DB_HOST=pgvector_db # Service name in docker-compose.yml
# PGVECTOR_DATA_VOLUME_PATH=./pgvector_data # Path to persist pgvector data on the host

# Redis Docker Configuration (Port mapping for host access if needed)

# --- AI Provider Configuration ---
# Choose the primary AI provider ("ollama" or "gemini")
AI_PROVIDER=ollama # Default to ollama

# --- Ollama Configuration (used if AI_PROVIDER=ollama) ---
OLLAMA_HOST=http://ollama:11434 # Service name for inter-container communication. For host access, use http://localhost:OLLAMA_HOST_PORT
OLLAMA_EMBEDDING_MODEL="nomic-embed-text" # Example, choose a suitable model available in your Ollama
OLLAMA_MARKDOWN_MODEL="llama3" # Example, for transforming to Markdown
OLLAMA_QA_MODEL="llama3" # Example, for RAG question answering
OLLAMA_CONTEXT_MODEL="llama3" # Example, for adding context to chunks

# --- Alternative AI Provider: Google Gemini (used if AI_PROVIDER=gemini) ---
GEMINI_API_KEY=your_google_ai_gemini_api_key # IMPORTANT: Replace with your actual key
GEMINI_EMBEDDING_MODEL=embedding-001
GEMINI_TEXT_MODEL=gemini-1.5-flash
GEMINI_VISION_MODEL=gemini-1.5-pro-vision
GEMINI_SAFETY_SETTINGS_ENABLED=True