# EntrenAI - VersiÃ³n Simplificada

EntrenAI simplificado y refactorizado para configurar asistentes de IA en cursos de Moodle.

## CaracterÃ­sticas

- **Simplificado**: CÃ³digo limpio, fÃ¡cil de entender y mantener
- **Modular**: Arquitectura basada en servicios independientes
- **Flexible**: Soporte para mÃºltiples proveedores de IA (Ollama, Gemini)
- **Eficiente**: Vector store con pgvector para bÃºsquedas semÃ¡nticas
- **FÃ¡cil deployment**: Docker Compose incluido

## Arquitectura

```
src/entrenai/
â”œâ”€â”€ config.py           # ConfiguraciÃ³n centralizada
â”œâ”€â”€ models.py           # Modelos de datos
â”œâ”€â”€ clients/            # Clientes para servicios externos
â”‚   â”œâ”€â”€ moodle.py      # Cliente de Moodle
â”‚   â””â”€â”€ n8n.py         # Cliente de N8N
â”œâ”€â”€ ai/                 # Proveedores de IA
â”‚   â””â”€â”€ providers.py   # Ollama y Gemini
â”œâ”€â”€ db/                 # Base de datos
â”‚   â””â”€â”€ vector_store.py # Store de vectores
â”œâ”€â”€ core/               # LÃ³gica de negocio
â”‚   â”œâ”€â”€ setup.py       # Setup de cursos
â”‚   â”œâ”€â”€ chat.py        # Servicio de chat
â”‚   â””â”€â”€ document_processor.py # Procesador de documentos
â””â”€â”€ api/                # API REST
    â””â”€â”€ main.py        # Endpoints principales
```

## InstalaciÃ³n RÃ¡pida

1. **Clonar y configurar**:
```bash
cd final/
cp .env.example .env
# Editar .env con tu configuraciÃ³n
```

2. **Levantar servicios**:
```bash
make services-up  # PostgreSQL + Redis
```

3. **Instalar dependencias**:
```bash
make install
```

4. **Ejecutar en desarrollo**:
```bash
make dev
```

## Uso Principal

### 1. Configurar IA para un curso

```bash
curl -X POST "http://localhost:8000/courses/123/setup" \
  -H "Content-Type: application/json" \
  -d '{"course_name": "Mi Curso"}'
```

### 2. Subir documentos

```bash
curl -X POST "http://localhost:8000/courses/123/documents/upload" \
  -F "files=@documento.pdf" \
  -F "files=@otro_archivo.txt"
```

### 3. Chat con contexto del curso

```bash
curl -X POST "http://localhost:8000/courses/123/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿CuÃ¡les son los objetivos del curso?"}'
```

## ConfiguraciÃ³n

### Variables de Entorno

- `AI_PROVIDER`: Proveedor de IA (`ollama` o `gemini`)
- `OLLAMA_HOST`: URL de Ollama (ej: `http://localhost:11434`)
- `GEMINI_API_KEY`: API Key de Google Gemini
- `MOODLE_URL`: URL de tu Moodle
- `MOODLE_TOKEN`: Token de API de Moodle

### Providers de IA

**Ollama (Local)**:
```env
AI_PROVIDER=ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
```

**Google Gemini**:
```env
AI_PROVIDER=gemini
GEMINI_API_KEY=tu_api_key
GEMINI_MODEL=gemini-pro
```

## Docker

**Todo en Docker**:
```bash
make up
```

**Solo servicios auxiliares**:
```bash
make services-up
make dev
```

## API Endpoints

- `POST /courses/{id}/setup` - Configurar IA para curso
- `GET /courses/{id}/status` - Estado de configuraciÃ³n
- `POST /courses/{id}/chat` - Chat con contexto
- `POST /courses/{id}/documents/upload` - Subir documentos
- `POST /courses/{id}/documents/text` - AÃ±adir texto directo
- `DELETE /courses/{id}/cleanup` - Limpiar configuraciÃ³n

## ComparaciÃ³n con VersiÃ³n Original

| Aspecto | Original | Simplificado |
|---------|----------|--------------|
| LÃ­neas de cÃ³digo | ~3000+ | ~800 |
| Archivos | 20+ | 8 principales |
| ConfiguraciÃ³n | MÃºltiples archivos | 1 archivo |
| Manejo de errores | Muy complejo | Esencial |
| Dependencias | 30+ | 10 |
| Setup bÃ¡sico | 100+ lÃ­neas | 30 lÃ­neas |

## CaracterÃ­sticas Mantenidas

âœ… Setup automÃ¡tico de cursos
âœ… Chat con contexto
âœ… Vector store para documentos  
âœ… MÃºltiples proveedores IA
âœ… IntegraciÃ³n con Moodle
âœ… Procesamiento de documentos

## Simplificaciones Realizadas

ðŸ”¹ Manejo de errores esencial (no exhaustivo)
ðŸ”¹ Clientes HTTP directos (sin capas extra)
ðŸ”¹ ConfiguraciÃ³n unificada
ðŸ”¹ Menos validaciones complejas
ðŸ”¹ CÃ³digo mÃ¡s directo y legible
